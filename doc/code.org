#+STARTUP: overview
#+SEQ_TODO: TODO(T) WAIT(W) | DONE(D!) CANCELED(C@) 
#+COLUMNS: %10ITEM  %10PRIORITY %15TODO %65TAGS

#+OPTIONS: toc:4 ^:{} num:nil creator:nil author:nil
#+OPTIONS: author:nil timestamp:nil d:nil
#+STYLE: <link rel="stylesheet" type="text/css" href="../css/style.css">

* code
** Signature
   - Camlp4Syntax
     It contains sub-modules: /Loc/, /Ast/, /Token/, /Gram/,
     /Quotation/, /AntiquotSyntax/
** Printers

   Signature for printer plugin:
   #+BEGIN_SRC caml
   module Printer (Ast : Ast) = struct
     module type S = sig
       value print_interf : ?input_file:string -> ?output_file:string ->
                            Ast.sig_item -> unit;
       value print_implem : ?input_file:string -> ?output_file:string ->
                            Ast.str_item -> unit;
     end;
   end;
   #+END_SRC
   - DumpCamlp4Ast
     Simple, simple marshalize camlp4ast
   - Null
     Do nothing
   - DumpOCamlpAst
     It makes use of the module =Struct.Camlp4Ast2OCamlAst.Make= to
     dump the binary output of ocamlast.
   - OCaml
     Dump to Ocaml's textual output
   - OCamlr Dump to Ocaml's revised textual output. It depends on the
     module OCaml.




** [[file:~/camlp4/src/FanLexer.mll][Lexer]]

   #+BEGIN_SRC ocaml
       (* To store some context information:
        *   loc       : position of the beginning of a string, quotation and comment
        *   in_comment: are we in a comment?
        *   quotations: shall we lex quotation?
        *               If quotations is false it's a SYMBOL token.
        *   antiquots : shall we lex antiquotations.
        *)
     
     type context =
       { loc        : Loc.t    ;
         in_comment : bool     ;
         quotations : bool     ;
         antiquots  : bool     ;
         lexbuf     : lexbuf   ;
         buffer     : Buffer.t }
     
     let default_context lb =
       { loc        = Loc.ghost ;
         in_comment = false     ;
         quotations = true      ;
         antiquots  = false     ;
         lexbuf     = lb        ;
         buffer     = Buffer.create 256 }
        
   #+END_SRC

   #+BEGIN_SRC ocaml
     val loc:context -> Loc.t
     val set_start_p:context -> unit
     val move_start_p : int -> context -> unit
     val with_curr_loc : (context -> Lexing.lexbuf -> 'a) -> context -> 'a
   #+END_SRC

*** state machine
    #+BEGIN_SRC ocaml
    val token : context -> Lexing.lexbuf -> FanSig.camlp4_token    
    #+END_SRC

**** when it meets '"'
    #+BEGIN_SRC ocaml
      { with_curr_loc string c;
        let s = buff_contents c in STRING (TokenEval.string s, s)}
    #+END_SRC

**** when it meets "'"

     #+BEGIN_SRC ocaml
       | "'" (newline as x) "'"
             { update_loc c None 1 false 1; CHAR (TokenEval.char x, x)               }
       | "'" ( [^ '\\' '\010' '\013']
             | '\\' (['\\' '"' 'n' 't' 'b' 'r' ' ' '\'']
                    |['0'-'9'] ['0'-'9'] ['0'-'9']
                    |'x' hexa_char hexa_char)
               as x) "'"                                { CHAR (TokenEval.char x, x) }
       | "'\\" (_ as c)
               { err (Illegal_escape (String.make 1 c)) (Loc.of_lexbuf lexbuf)         }     
     #+END_SRC

     

**** when it meets "(*"

     #+BEGIN_SRC ocaml
       | "(*"
           { store c; COMMENT(parse_nested comment (in_comment c))                 }
       | "(*)"
           { warn Comment_start (Loc.of_lexbuf lexbuf)                             ;
             parse comment (in_comment c); COMMENT (buff_contents c)               }
       | "*)"
           { warn Comment_not_end (Loc.of_lexbuf lexbuf)                           ;
             move_start_p (-1) c; SYMBOL "*"                                       }
       
     #+END_SRC     
     So we go into the comment state
**** when it meets quotation
     #+BEGIN_SRC ocaml
       | "<<" (quotchar* as beginning)
              { if quotations c
                then (move_start_p (-String.length beginning) c; (* FIX partial application*)
                      mk_quotation quotation c "" "" 2)
                else parse (symbolchar_star ("<<" ^ beginning)) c                       }
       | "<<>>"
           { if quotations c
             then QUOTATION { q_name = ""; q_loc = ""; q_shift = 2; q_contents = "" }
             else parse (symbolchar_star "<<>>") c                                   }
       | "<@"
           { if quotations c then with_curr_loc maybe_quotation_at c
             else parse (symbolchar_star "<@") c                                     }
       | "<:"
           { if quotations c then with_curr_loc maybe_quotation_colon c
             else parse (symbolchar_star "<:") c                                     }
            
     #+END_SRC

     The complexity appears here when we want to handle both
     quotations and noquotations support.

     #+BEGIN_SRC ocaml
       mk_quotation: (context -> Lexing.lexbuf -> unit) ->
         context -> string -> string -> int -> FanSig.camlp4_token     
     #+END_SRC
     #+BEGIN_SRC ocaml
     maybe_quotation_at:context -> Lexing.lexbuf -> FanSig.camlp4_token
     #+END_SRC

**** meets "#"

     #+BEGIN_SRC ocaml
       | "#" [' ' '\t']* (['0'-'9']+ as num) [' ' '\t']*
        ("\"" ([^ '\010' '\013' '"' ] * as name) "\"")?
        [^ '\010' '\013'] * newline
       { let inum = int_of_string num in
         update_loc c name inum true 0; LINE_DIRECTIVE(inum, name) }
     #+END_SRC
     
**** ESCAPEd_INDENT
     #+BEGIN_SRC ocaml
       | '(' (not_star_symbolchar as op) ')'
             { ESCAPED_IDENT (String.make 1 op) }
       | '(' (not_star_symbolchar symbolchar* not_star_symbolchar as op) ')'
             { ESCAPED_IDENT op }
       | '(' (not_star_symbolchar symbolchar* as op) blank+ ')'
                                                              { ESCAPED_IDENT op }
       | '(' blank+ (symbolchar* not_star_symbolchar as op) ')'
                                                            { ESCAPED_IDENT op }
       | '(' blank+ (symbolchar+ as op) blank+ ')'
                                                 { ESCAPED_IDENT op }
            
     #+END_SRC

     
**** symbol
     #+BEGIN_SRC ocaml
       | ( "#"  | "`"  | "'"  | ","  | "."  | ".." | ":"  | "::"
           | ":=" | ":>" | ";"  | ";;" | "_"
           | left_delimitor | right_delimitor ) as x  { SYMBOL x }
       | '$' { if antiquots c
               then with_curr_loc dollar (shift 1 c)
               else parse (symbolchar_star "$") c }
       | ['~' '?' '!' '=' '<' '>' '|' '&' '@' '^' '+' '-' '*' '/' '%' '\\'] symbolchar *
         as x { SYMBOL x }
            
     #+END_SRC
*** utilities
    =store= store current lexeme into  =c.buffer=
    =istore_char= stores ith char in the lexeme into =c.buffer=
    =buffer_contents= return the buffer contents and reset the buffer
    =loc= returns the current location(wider)
    =in_comment= sets the =in_comment= state to true

    =set_start_p= sets the =c.lexbuf.lex_start_p=

    =move_start_p= moves the =start= shift in one line (if not in the
    same line, may be buggy)

    
*** special case
    #+BEGIN_SRC ocaml
      '
      ';;
      - : char = '\n'
      
    #+END_SRC



*** bugs to be fixed

**** quotation
     - comment in quotation
       we require comment quotation is also correct, so there's nothing
       to be fixed here
     - string in quotation
       fixed 
     - newline
       no need to fix


**** antiquotation
     - string in antiquot
     - quot in antiquot


**** cautious
     take care $(m.app) parenthesese is need
** Gramar

   #+BEGIN_SRC ocaml
     module type Action = sig
         type t
         val  mk: 'a -> t
         val get: t -> 'a
         val getf: t -> ('a->'b)
         val getf2: t -> ('a->'b->'c)
       end
     type assoc = NonA | LeftA | RightA
     type position =
         First
       | Last
       | Before of string
       | After of string
       | Level of string
     
     module type Structure =  sig
         module Loc: FanSig.Loc
         module Action:Action
         module Token: FanSig.Token with module Loc = Loc
     
         (* more like global information related to lexer *)                                               
         type gram = {
           gfilter: Token>Filter.t;
           gkeywords: Hashtbl.t string (ref int);
           glexer: Loc.t -> Stream.t char -> Stream.t (Token.t * Loc.t);
           waring_verbose: ref bool;
           error_verbose: ref bool;
         }
         type efun = token_stream -> Action.t
         type token_pattern = ((Token.t -> bool) * string)
                                
         type internal_array ={
           egram: gram;
           ename: string;
           mutable estart: int -> efun ;
           mutable econtinue: int -> Loc.t -> Action.t -> efun;
           mutable edesc: desc }
         and desc =
            Dlevels of list level
            | Dparser of token_stream -> Action.t
         and level = {
           assoc: assoc;
           lname: string option;
           lsuffix: tree;
           lprefix: tree
         }
         and symbol = 
             Smeta of string * list symbol * Action.t (* Action.t *)
           | Snterm of internal_entry (* internal_array *)
           | Snterml of internal_entry * string
           | Slist0 of symbol
           | Slist0sep of symbol * symbol
           | Slist1 of symbol
           | Slist1sep of symbol * symbol
           | Sopt of symbol
           | Stry of symbol
           | Sself of symbol
           | Snext
           | Stoken of token_pattern (* a function *)
           | Skeyword of string
           | Stree of tree
         and tree =
           Node of node
           | LocAct of Action.t * Action.t list
           | DeadEnd
         and node  ={
           node: symbol;
           son: tree;
           brother: tree
         }
         type token_info = {
           prev_loc: Loc.t;
           cur_loc: Loc.t;
           prev_loc_only: bool;
         }
         type production_rule = (list symbol * Action.t )
         type signle_extend_statement =
             (string option * assoc option * production_rule list )
         type extend_statement = (position option * single_extend_statement list)
         type delete_statement = list symbol
                             
         type token_stream = Stream.t (Token.t * token_info)
         val token_location: token_info -> Loc.t
     
         type fold 'a 'b 'c =
             internal_entry -> symbol list -> ('a Stream.t -> 'b) ->  'a Stream.t -> 'c
         type foldsep 'a 'b 'c =
             internal_entry -> symbol list -> ('a Stream.t -> 'b) -> ('a Stream.t -> unit) -> 'a Stream.t -> 'c
       end
     
     (* Dynamic means that you can produce as many grammar values as needed with a signle grammar module
        If you do not need many grammar values it's preferable to use a static one
      *)                           
     module type  Dynamic = sig
         include Structure
         val mk: unit -> gram
         module Entry : sig
           type 'a t
           val mk : gram -> string -> 'a t
           val of_parser: gram -> string -> (token_stream -> 'a ) -> 'a t
     
           (* clear the entry and setup this parser instead *)                                                                   
           val setup_parser:
             'a t -> (token_stream -> 'a) -> unit
           val name: 'a t -> string
           val print: Format.formatter -> 'a t -> unit
     
           (* same as {!print} but shows the left factorization
                {[
                 Gram.Entry.dump std_formatter Syntax.expr
                ]}
            *)                                         
           val dump: Format.formatter -> 'a t -> unit
           val obj: 'a t -> internal_entry
           val clear: 'a t -> unit
         end
         val get_filter: gram -> Token.Filter.t
         type not_filtered 'a
     
         val extend: 'a Entry.t -> extend_statement -> unit
         val delete_rule: 'a Entry.t -> delete_statement -> unit
         val srules: 'a Entry.t -> (symbol list * Action.t) list -> symbol
         val sfold0: ('a->'b ->'b) -> 'b -> fold _ 'a 'b
         val sfold1: ('a->'b -> 'b) -> 'b -> fold _ 'a 'b
         val sfold0sep: ('a -> 'b -> 'b) -> 'b -> foldsep _ 'a 'b
     
         (* use the lexer to produce  a non filtered token stream from a char stream  *)                                                     
         val lex: gram -> Loc.t -> char Stream.t -> ((Token.t * Loc.t) Stream.t) not_filtered 
         val lex_string: gram - Loc.t -> string -> ((Token.t * Loc.t) Stream.t) not_filtered 
                                                                
         val filter: gram -> not_filtered ((Token.t * Loc.t)Stream.t)  -> token_stream
     
         val parse: 'a Entry.t -> Loc.t -> char Stream.t -> 'a
         val parse_string: 'a Entry.t -> Loc.t -> string -> 'a
     
         val parse_tokens_before_filter: 'a Entry.t -> not_filtered ((Token.t*Loc.t) Stream.t) -> 'a
         val parse_tokens_after_filter: 'a Entry.t -> token_stream -> 'a
       end
     
     
     (* There's only one grammar value by grammar module *)                         
     module type Static = sig
         include Structure
         val trace_parser: ref bool
         val gram: gram;
         module Entry : sig
           type 'a t
           val mk:string -> t 'a
           val of_parser:
             string -> (token_stream -> 'a) -> 'a t
           val setup_parser: 'a t -> (token_stream ->'a) -> unit
           val name: 'a t -> string
           val print: Format.formatter -> 'a t -> unit
           val dump: Format.formatter -> 'a t -> unit
           val obj: 'a t -> internal_entry
           val clear: 'a t -> unit
         end
         val get_filter: unit -> Token.Filter.t
         type 'a not_filtered
         val extend: 'a Entry.t -> extend_statement -> unit
         val delete_rule: 'a Entry.t -> delete_statement -> unit
         val srules: 'a Entry.t -> (symbol list * Action.t) list -> symbol
         val sfold0: ('a->'b ->'b) -> 'b -> fold _ 'a 'b
         val sfold1: ('a->'b -> 'b) -> 'b -> fold _ 'a 'b
         val sfold0sep: ('a -> 'b -> 'b) -> 'b -> foldsep _ 'a 'b
     
         (* use the lexer to produce  a non filtered token stream from a char stream  *)                                                     
         val lex: gram -> Loc.t -> char Stream.t -> ((Token.t * Loc.t) Stream.t) not_filtered 
         val lex_string: gram - Loc.t -> string -> ((Token.t * Loc.t) Stream.t) not_filtered 
                                                                
         val filter: gram -> not_filtered ((Token.t * Loc.t)Stream.t)  -> token_stream
     
         val parse: 'a Entry.t -> Loc.t -> char Stream.t -> 'a
         val parse_string: 'a Entry.t -> Loc.t -> string -> 'a
     
         val parse_tokens_before_filter: 'a Entry.t -> not_filtered ((Token.t*Loc.t) Stream.t) -> 'a
         val parse_tokens_after_filter: 'a Entry.t -> token_stream -> 'a
       end
   #+END_SRC

**** grammar

     #+BEGIN_SRC ocaml
       expr: AFTER "top"
         [ [ "EXTEND"; e = extend_body; "END" -> e
           | "DELETE_RULE"; e = delete_rule_body; "END" -> e ]
         ];
       
       extend_body:
         [ [ (gram,g) = extend_header; global_list=OPT global;
             el = LIST1 [e=entry; semi_sep -> e] ->
                  text_of_functorial_extend _loc g gram global_list el
         ]];
       
       extend_header:
         [ [ "("; i= qualid; ":"; t = t_qualid; ")" -> (Some i,t)
           | g = qualuid -> (None,g) (* Gram *) ]
         ];
       
       qualuid:
         [ [ x = UIDENT ; "."; xs = SELF -> <:ident< $uid:x.$xs >>
           | i = UIDENT -> <:ident< $uid:i >> 
             
           ]];
       
       qualid:
         [ [  x = UIDENT; "."; xs = SELF  -> <:ident< $uid:x.$xs >>
           |  i = UIDENT -> <:ident< $uid:i >>
           |  u = LIDENT -> <:ident< $lid:i >> 
         ]];
       
       t_qualid:
         [ [ x = UIDENT; "."; xs = SELF -> <:ident< $uid:x.$xs >>
           | x = UIDENT; "."; `LIDENT "t" -> <:ident< $uid:x >>
           | `(LIDENT _ | UIDENT _ ) ->
              Loc.raise
                _loc
                (Stream.Error
                   "Wrong EXTEND header, the grammar type must finish by 't' \
                    like in EXTEND (g:Gram.t) ... END "
                             )
         ]];
       global:
         [ [ UIDENT "GLOBAL"; ":"; sl = LIST1 name; semi_sep -> sl ]];
       
       name:
         [ [ il = qualid -> mk_name _loc il ]];
       
       entry:
         [ [ n = name; ":"; pos = OPT position; ll = level_list -> (* "entry" here is the name *)
            {name=n;pos=pos; levels = ll} (* (Ast.expr,Ast.patt) entry entry was defined locally*)
                                         
         ]];
       position:
         [ [ UIDENT "FIRST"  -> <:expr< Camlp4.Sig.Grammar.First >>
           | UIDENT "LAST"   -> <:expr< Camlp4.Sig.Grammar.Last >>
           | UIDENT "BEFORE"; n = string -> <:expr< Camlp4.Sig.Grammar.Before $n >>
           | UIDENT "AFTER";  n = string -> <:expr< Camlp4.Sig.Grammar.After $n >>
           | UIDENT "LEVEL";  n = string -> <:expr< Camlp4.Sig.Grammar.Level $n >> 
         ]];
       level_list:
         [ [ "["; ll = LIST0 level SEP "|"; "]" -> ll ]];
       
       level:
         [ [ lab = OPT [ x = STRING -> x ]; ass = OPT assoc; rules = rule_list ->
             {label = lab; assoc = ass; rules = rules} (* (Ast.expr, Ast.patt) level *) ]];
       assoc:
         [ [ UIDENT "LEFTA" -> <:expr< Camlp4.Sig.Grammar.LeftA >>
           | UIDENT "RIGHTA" -> <:expr< Camlp4.Sig.Grammar.RightA >>
           | UIDENT "NONA"  -> <:expr< Camlp4.Sig.Grammar.NonA >>
         ] ];
       
       rule_list:
         [ ["["; "]" -> []
           | "["; rules = LIST1 rule SEP "|"; "]" ->
              retype_rule_list_without_patterns _loc rules
         ]];
       
       rule:
         [ [ ps1 = LIST0 psymbol SEP semi_sep; "->"; act = expr ->
             {prod = psl; action = Some act }
           | psl = LIST0 psymbol SEP semi_sep -> (* none action allowed actually *)
             {prod = psl; action = None} (* (Ast.expr,Ast.patt) rule *)
         ]];
       
       psymbol:
         [ [ p = LIDENT; "=" s = symbol ->
             match s.pattern with
             [ Some (<:patt<  $uid:u $(tup:<:patt< _ >> ) >>  as p') ->
               let match_fun = <:expr< fun [ $pat:p' -> True | _ -> False ] >> in
               let p' = <:patt< ($p' as $lid:p) >> in
               let descr = u ^ "_" in
               let text = TXtok _loc match_fun descr in
               { (s) with pattern =  Some <:patt< $lid:p >> }
             | i = LIDENT; lev = OPT [UIDENT "LEVEL"; s = STRING -> s] ->
                let name = mk_name _loc <:ident< $lid:i >> in
                let text = TXnterm _loc name lev in
                let styp = STquo _loc i in
                {used=[i]; text =text; styp=styp; pattern = None }
             | p = pattern; "="; s = symbol ->
                match s.pattern with
                [ Some <:patt< $uid:u $(tup: <:patt< _ >> ) >> ->
                  mk_tok _loc <:patt< $uid:u $p >> s.styp
                | _ -> { (s) with pattern = Some p }]
             | s = symbol -> s
             ]
         ]];
       
       symbol
         [ "top" NONA
            [UIDENT "LIST0"; s = SELF ; sep = OPT [UIDENT "SEP"; t = symbol -> t] ->
             let () = check_not_tok s in
             let used = match sep with
                 [ Some symb -> symb.used @ s.used
                 | None -> s.used] in
             let styp = STapp _loc (STlid _loc "list") s.styp in
             let text = slist _loc False sep s in 
             {used=s.used; text = text; styp=s.styp; pattern = None}
            | UIDENT "LIST1"; s=SELF; sep = OPT [UIDENT "SEP"; t=symbol -> t] ->
               let () = check_not_tok s in
               let used = match sep with
                   [ Some symb -> symb.used @ s.used
                   | None -> s.used ] in
               let styp = STapp _loc (STlid _loc "list") s.styp in
               let text = slist _loc True sep in
               {used=s.used; text = text; styp=s.styp; pattern = None}
            | UIDENT "TRY"; s = SELF ->
               let text = TXtry _loc s.text in
               {used=s.used; text = text; styp=s.styp; pattern = None} ]
            
          | [  UIDENT "SELF" ->
               {used=[]; text = TXnext _loc; styp = STself _loc "SELF"; pattern = None }
            |  UIDENT "NEXT" ->
               {used= []; text = TXnext _loc; styp = STself _loc "NEXT"; pattern = None}
       
            | "[";  r1 = LIST0 rule SEP "|"; "]" ->
               let r1 = retype_rule_list_without_patterns _loc r1 in
               let t = new_type_var () in
               {used = used_of_rule_list rl;
                text = TXrules _loc (srules _loc t rl "");
                styp = STquo _loc t;
                pattern = None
               }
       
            | "`"; p=patt -> mk_tok _loc p (STtok _loc)
       
            | x = UIDENT -> mk_tok _loc <:patt< $uid:x $(tup:<:patt< _ >> ) >>
            | x = UIDENT; s=STRING -> mk_tok _loc <:patt< $uid:x $str:x >> (STtok _loc)
       
            (* A $v *)                                                                 
            | x = UIDENT; `ANTIQUOT "" s ->
               let e = AntiquotSyntax.parse_expr _loc s in
               let match_fun = <:expr< fun [$uid:x camlp4_x when camlp4_x = $e -> True | _ -> False ] >> in
               let descr = "$" ^ x ^ " " ^ s in
               let text = TXtok _loc match_fun descr in
               let p = <:patt< $uid:x $(tup:<:patt< _ >> ) in
               {used=[]; text=text;styp=STtok _loc; pattern=Some p}
            | s = STRING -> { used=[]; text= TXkwd _loc s ; styp= STtok _loc ; pattern = None }
            | i = UIDENT; "."; il = qualid ;  lev = OPT [UIDENT "LEVEL"; s=STRING -> s] ->
               let n = mk_name _loc <:ident< $uid:i.$il >> in
               {used=[n.tvar]; text = TXnterm _loc n lev; styp = STquo _loc n.tvar; pattern = None }
                 
            | n = name; lev = OPT [UIDENT "LEVEL"; s=STRING -> s] ->
               {used = [n.tvar]; text = TXnterm _loc n lev; styp = STquo _loc n.tvar; pattern  = None}
       
            | "("; s_t = SELF; ")" -> s_t ]
            ];  (* symbol is the key to understand *)
       
       pattern:
         [ [ i=LIDENT -> <:patt< $lid:i >>
           | "_" -> <:patt< _ >>
           | "("; p=pattern; ")" -> <:patt< $p >>
           | "("; p1=pattern; ","; p2= comma_patt; ")" -> <:patt< ($p1,$p2) >>                                
           | p = pattern -> p ]];
       
       comma_patt:
         [ [ p1=SELF; ","; p2=SELF -> <:patt< $p1,$p2 >>
           | p = pattern -> p 
         ]];
       
       name:
         [[ il = qualid -> mk_name _loc il ]];
       
       string:
         [[ s = STRING -> <:expr< $str:s >>
          | `ANTIQUOT "" s -> AntiquotSyntax.parse_expr _loc s ]];
       
       semi_sep:
         [[ ";" -> ()]];
     #+END_SRC
** TODO Register mechanism

   (string,module Sig.PLUGIN) Hashtbl.t

   -parsers
   comman_or_blank_sep_strings [[file:~/ocaml/ocamlbuild/lexers.mli][lexer]]
   delayed

   
* ideas
  

** take a look at design of xstrp4
   how to make
   =/fprintf ppf "ghso" more simple /=

   =/<:fmt<Illegal character ($(Char.escaped c))>>/=

   the quotation fmt can config which "fprintf" was used actually,
   like "bprintf", "ifprintf", "eprintf"
** integrating ulex
   an extensible lexer?
